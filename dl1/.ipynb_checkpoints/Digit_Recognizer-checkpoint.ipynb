{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kaggle: Digit Recognizer\n",
    "\n",
    "Learn computer vision fundamentals with the famous MNIST data.\n",
    "\n",
    "比赛页面：https://www.kaggle.com/c/digit-recognizer\n",
    "\n",
    "参考Kernel：\n",
    "\n",
    "[Introduction to CNN Keras - 0.997 (top 6%)](https://www.kaggle.com/yassineghouzam/introduction-to-cnn-keras-0-997-top-6)\n",
    "\n",
    "[Training your own CNN using PyTorch](https://www.kaggle.com/puneetgrover/training-your-own-cnn-using-pytorch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由于数据集是Kaggle提供的，不同于深度学习框架自带的MINIST，因此需要自己对数据做预处理，自己写数据加载器。\n",
    "\n",
    "这是第一次打Kaggle的视觉比赛，先走个流程。\n",
    "\n",
    "大概分这么几个步骤：\n",
    "\n",
    "1. 对CSV数据文件做预处理，分割训练集和验证集，写DataLoader\n",
    "2. 调用Pytorch model自带的CNN模型或者自定义模型进行训练\n",
    "3. 测试评估模型\n",
    "4. 对测试集进行预测，进行提交"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 导入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-02T13:23:58.600877Z",
     "start_time": "2018-11-02T13:23:58.568707Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch \n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "# 拓展包\n",
    "import torchsample as ts\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据预处理\n",
    "\n",
    "1. 读取数据（训练集和验证集），维度检查\n",
    "2. 分割数据集\n",
    "3. 自定义DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 读取数据，维度检查"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    4684\n",
       "7    4401\n",
       "3    4351\n",
       "9    4188\n",
       "2    4177\n",
       "6    4137\n",
       "0    4132\n",
       "4    4072\n",
       "8    4063\n",
       "5    3795\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 加载数据\n",
    "train = pd.read_csv(\"./data/train.csv\")\n",
    "test = pd.read_csv(\"./data/test.csv\")\n",
    "\n",
    "Y_train = train[\"label\"]\n",
    "\n",
    "# 丢掉第一栏label\n",
    "X_train = train.drop(labels = [\"label\"], axis = 1)\n",
    "\n",
    "# 查看数据分布\n",
    "g = sns.countplot(Y_train)\n",
    "Y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 784)\n",
      "(42000,)\n",
      "(28000, 784)\n"
     ]
    }
   ],
   "source": [
    "# 查看维度\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-16e2d70544dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# test = test.values.reshape(-1,1,28,28)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mY_train\u001b[0m  \u001b[0;34m=\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "# 将Padas数据结构转换为numpy\n",
    "# reshape为单通道图像（28*28*1）\n",
    "\n",
    "# X_train = X_train.values.reshape(-1,1,28,28)\n",
    "# Y_train  =Y_train.values\n",
    "# test = test.values.reshape(-1,1,28,28)\n",
    "\n",
    "X_train = X_train.values.reshape(-1,28,28)\n",
    "Y_train  =Y_train.values\n",
    "test = test.values.reshape(-1,28,28)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 分割数据集和验证集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置随机种子\n",
    "random_seed = 5\n",
    "\n",
    "# 分割测试集和验证集\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.1, random_state=random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37800, 28, 28)\n",
      "(4200, 28, 28)\n",
      "(37800,)\n",
      "(4200,)\n"
     ]
    }
   ],
   "source": [
    "# 查看维度\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f233164e2b0>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 展示案例\n",
    "plt.imshow(X_train[0])\n",
    "# image = Image.fromarray(np.uint8(X_train[0]))\n",
    "# plt.imshow(np.asarray(image))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 自定义Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 都是针对PIL Image的\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "#     transforms.Resize(256),\n",
    "#     transforms.RandomCrop(224),\n",
    "    transforms.RandomRotation(20),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "#     ts.transforms.RandomRotate(20),\n",
    "#     ts.transforms.RandomTranslate(0.1,0.1),\n",
    "#     transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建自定义数据加载类\n",
    "class MINISTDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, images = None, labels = None, transfrom=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transfrom= transfrom\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        image = self.images[index]\n",
    "        image = Image.fromarray(np.uint8(image))\n",
    "#         image = image.convert('RGB')\n",
    "        label = self.labels[index]\n",
    "        \n",
    "        \n",
    "        #  2. 预处理数据（比如使用 torchvision.Transform）\n",
    "        if self.transfrom:\n",
    "            image = self.transfrom(image)\n",
    "            \n",
    "        # 3. 返回数据对（比如 image和label）\n",
    "        return (image, label)\n",
    "    \n",
    "    def __len__(self):\n",
    "        # 将0替换成数据集的总长度\n",
    "        count = len(self.images)\n",
    "        return count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 建立CNN模型进行训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 超参数设置\n",
    "num_epochs = 50\n",
    "num_classes = 10\n",
    "batch_size = 64\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设备配置\n",
    "torch.cuda.set_device(1) # 这句用来设置pytorch在哪块GPU上运行\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置训练集和验证集\n",
    "train_set = MINISTDataset(images=X_train, labels=Y_train,transfrom=preprocess)\n",
    "train_loader  = torch.utils.data.DataLoader(dataset=train_set,\n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "val_set = MINISTDataset(images =X_val, labels=Y_val, transfrom=preprocess )\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_set,\n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 迭代的使用\n",
    "# 当迭代开始时，队列和线程开始从文件中加载数据\n",
    "data_iter = iter(train_loader)\n",
    "\n",
    "# 获取一组mini-batch\n",
    "images, labels = data_iter.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolutional neural network (two convolutional layers)\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.fc = nn.Linear(7*7*32, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自建模型\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(CNN, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 32, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Dropout2d(0.25))\n",
    "        \n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, kernel_size=5, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Dropout2d(0.25))\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(7*7*128, 256),\n",
    "            nn.Dropout2d(0.25),\n",
    "            nn.Linear(256, num_classes))\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建模型实例\n",
    "model = ConvNet(num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 损失函数和优化器\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Step [100/591], Loss: 0.2546\n",
      "Epoch [1/50], Step [200/591], Loss: 0.5350\n",
      "Epoch [1/50], Step [300/591], Loss: 0.2688\n",
      "Epoch [1/50], Step [400/591], Loss: 0.2134\n",
      "Epoch [1/50], Step [500/591], Loss: 0.3210\n",
      "Epoch [2/50], Step [100/591], Loss: 0.1524\n",
      "Epoch [2/50], Step [200/591], Loss: 0.0956\n",
      "Epoch [2/50], Step [300/591], Loss: 0.0802\n",
      "Epoch [2/50], Step [400/591], Loss: 0.2139\n",
      "Epoch [2/50], Step [500/591], Loss: 0.1441\n",
      "Epoch [3/50], Step [100/591], Loss: 0.0792\n",
      "Epoch [3/50], Step [200/591], Loss: 0.1044\n",
      "Epoch [3/50], Step [300/591], Loss: 0.2517\n",
      "Epoch [3/50], Step [400/591], Loss: 0.1473\n",
      "Epoch [3/50], Step [500/591], Loss: 0.2498\n",
      "Epoch [4/50], Step [100/591], Loss: 0.0066\n",
      "Epoch [4/50], Step [200/591], Loss: 0.0310\n",
      "Epoch [4/50], Step [300/591], Loss: 0.1400\n",
      "Epoch [4/50], Step [400/591], Loss: 0.1412\n",
      "Epoch [4/50], Step [500/591], Loss: 0.1200\n",
      "Epoch [5/50], Step [100/591], Loss: 0.1417\n",
      "Epoch [5/50], Step [200/591], Loss: 0.0469\n",
      "Epoch [5/50], Step [300/591], Loss: 0.0675\n",
      "Epoch [5/50], Step [400/591], Loss: 0.0927\n",
      "Epoch [5/50], Step [500/591], Loss: 0.1280\n",
      "Epoch [6/50], Step [100/591], Loss: 0.1273\n",
      "Epoch [6/50], Step [200/591], Loss: 0.1237\n",
      "Epoch [6/50], Step [300/591], Loss: 0.1131\n",
      "Epoch [6/50], Step [400/591], Loss: 0.1453\n",
      "Epoch [6/50], Step [500/591], Loss: 0.0511\n",
      "Epoch [7/50], Step [100/591], Loss: 0.1623\n",
      "Epoch [7/50], Step [200/591], Loss: 0.0234\n",
      "Epoch [7/50], Step [300/591], Loss: 0.0065\n",
      "Epoch [7/50], Step [400/591], Loss: 0.0400\n",
      "Epoch [7/50], Step [500/591], Loss: 0.0135\n",
      "Epoch [8/50], Step [100/591], Loss: 0.0832\n",
      "Epoch [8/50], Step [200/591], Loss: 0.0726\n",
      "Epoch [8/50], Step [300/591], Loss: 0.0311\n",
      "Epoch [8/50], Step [400/591], Loss: 0.0558\n",
      "Epoch [8/50], Step [500/591], Loss: 0.0122\n",
      "Epoch [9/50], Step [100/591], Loss: 0.0389\n",
      "Epoch [9/50], Step [200/591], Loss: 0.0393\n",
      "Epoch [9/50], Step [300/591], Loss: 0.0158\n",
      "Epoch [9/50], Step [400/591], Loss: 0.2017\n",
      "Epoch [9/50], Step [500/591], Loss: 0.0199\n",
      "Epoch [10/50], Step [100/591], Loss: 0.0397\n",
      "Epoch [10/50], Step [200/591], Loss: 0.0981\n",
      "Epoch [10/50], Step [300/591], Loss: 0.0462\n",
      "Epoch [10/50], Step [400/591], Loss: 0.0157\n",
      "Epoch [10/50], Step [500/591], Loss: 0.1176\n",
      "Epoch [11/50], Step [100/591], Loss: 0.0110\n",
      "Epoch [11/50], Step [200/591], Loss: 0.0119\n",
      "Epoch [11/50], Step [300/591], Loss: 0.0218\n",
      "Epoch [11/50], Step [400/591], Loss: 0.0582\n",
      "Epoch [11/50], Step [500/591], Loss: 0.0409\n",
      "Epoch [12/50], Step [100/591], Loss: 0.0164\n",
      "Epoch [12/50], Step [200/591], Loss: 0.3042\n",
      "Epoch [12/50], Step [300/591], Loss: 0.0294\n",
      "Epoch [12/50], Step [400/591], Loss: 0.1562\n",
      "Epoch [12/50], Step [500/591], Loss: 0.0179\n",
      "Epoch [13/50], Step [100/591], Loss: 0.0488\n",
      "Epoch [13/50], Step [200/591], Loss: 0.0588\n",
      "Epoch [13/50], Step [300/591], Loss: 0.0108\n",
      "Epoch [13/50], Step [400/591], Loss: 0.0243\n",
      "Epoch [13/50], Step [500/591], Loss: 0.0122\n",
      "Epoch [14/50], Step [100/591], Loss: 0.0054\n",
      "Epoch [14/50], Step [200/591], Loss: 0.0812\n",
      "Epoch [14/50], Step [300/591], Loss: 0.0612\n",
      "Epoch [14/50], Step [400/591], Loss: 0.0714\n",
      "Epoch [14/50], Step [500/591], Loss: 0.0719\n",
      "Epoch [15/50], Step [100/591], Loss: 0.0134\n",
      "Epoch [15/50], Step [200/591], Loss: 0.0277\n",
      "Epoch [15/50], Step [300/591], Loss: 0.2295\n",
      "Epoch [15/50], Step [400/591], Loss: 0.0362\n",
      "Epoch [15/50], Step [500/591], Loss: 0.0197\n",
      "Epoch [16/50], Step [100/591], Loss: 0.0320\n",
      "Epoch [16/50], Step [200/591], Loss: 0.0304\n",
      "Epoch [16/50], Step [300/591], Loss: 0.1203\n",
      "Epoch [16/50], Step [400/591], Loss: 0.1441\n",
      "Epoch [16/50], Step [500/591], Loss: 0.0677\n",
      "Epoch [17/50], Step [100/591], Loss: 0.2456\n",
      "Epoch [17/50], Step [200/591], Loss: 0.0678\n",
      "Epoch [17/50], Step [300/591], Loss: 0.0220\n",
      "Epoch [17/50], Step [400/591], Loss: 0.0269\n",
      "Epoch [17/50], Step [500/591], Loss: 0.0909\n",
      "Epoch [18/50], Step [100/591], Loss: 0.0259\n",
      "Epoch [18/50], Step [200/591], Loss: 0.0043\n",
      "Epoch [18/50], Step [300/591], Loss: 0.0415\n",
      "Epoch [18/50], Step [400/591], Loss: 0.0179\n",
      "Epoch [18/50], Step [500/591], Loss: 0.1326\n",
      "Epoch [19/50], Step [100/591], Loss: 0.0140\n",
      "Epoch [19/50], Step [200/591], Loss: 0.0826\n",
      "Epoch [19/50], Step [300/591], Loss: 0.0257\n",
      "Epoch [19/50], Step [400/591], Loss: 0.0167\n",
      "Epoch [19/50], Step [500/591], Loss: 0.0572\n",
      "Epoch [20/50], Step [100/591], Loss: 0.1176\n",
      "Epoch [20/50], Step [200/591], Loss: 0.0810\n",
      "Epoch [20/50], Step [300/591], Loss: 0.0345\n",
      "Epoch [20/50], Step [400/591], Loss: 0.0327\n",
      "Epoch [20/50], Step [500/591], Loss: 0.0124\n",
      "Epoch [21/50], Step [100/591], Loss: 0.0449\n",
      "Epoch [21/50], Step [200/591], Loss: 0.0239\n",
      "Epoch [21/50], Step [300/591], Loss: 0.0175\n",
      "Epoch [21/50], Step [400/591], Loss: 0.0845\n",
      "Epoch [21/50], Step [500/591], Loss: 0.0765\n",
      "Epoch [22/50], Step [100/591], Loss: 0.0029\n",
      "Epoch [22/50], Step [200/591], Loss: 0.0473\n",
      "Epoch [22/50], Step [300/591], Loss: 0.0212\n",
      "Epoch [22/50], Step [400/591], Loss: 0.0121\n",
      "Epoch [22/50], Step [500/591], Loss: 0.1266\n",
      "Epoch [23/50], Step [100/591], Loss: 0.0207\n",
      "Epoch [23/50], Step [200/591], Loss: 0.0539\n",
      "Epoch [23/50], Step [300/591], Loss: 0.0276\n",
      "Epoch [23/50], Step [400/591], Loss: 0.0496\n",
      "Epoch [23/50], Step [500/591], Loss: 0.0182\n",
      "Epoch [24/50], Step [100/591], Loss: 0.1432\n",
      "Epoch [24/50], Step [200/591], Loss: 0.1068\n",
      "Epoch [24/50], Step [300/591], Loss: 0.0241\n",
      "Epoch [24/50], Step [400/591], Loss: 0.1827\n",
      "Epoch [24/50], Step [500/591], Loss: 0.0400\n",
      "Epoch [25/50], Step [100/591], Loss: 0.0248\n",
      "Epoch [25/50], Step [200/591], Loss: 0.0169\n",
      "Epoch [25/50], Step [300/591], Loss: 0.0279\n",
      "Epoch [25/50], Step [400/591], Loss: 0.1071\n",
      "Epoch [25/50], Step [500/591], Loss: 0.0180\n",
      "Epoch [26/50], Step [100/591], Loss: 0.0207\n",
      "Epoch [26/50], Step [200/591], Loss: 0.0293\n",
      "Epoch [26/50], Step [300/591], Loss: 0.0268\n",
      "Epoch [26/50], Step [400/591], Loss: 0.0218\n",
      "Epoch [26/50], Step [500/591], Loss: 0.0243\n",
      "Epoch [27/50], Step [100/591], Loss: 0.0049\n",
      "Epoch [27/50], Step [200/591], Loss: 0.0290\n",
      "Epoch [27/50], Step [300/591], Loss: 0.0046\n",
      "Epoch [27/50], Step [400/591], Loss: 0.0014\n",
      "Epoch [27/50], Step [500/591], Loss: 0.1797\n",
      "Epoch [28/50], Step [100/591], Loss: 0.1043\n",
      "Epoch [28/50], Step [200/591], Loss: 0.0161\n",
      "Epoch [28/50], Step [300/591], Loss: 0.0200\n",
      "Epoch [28/50], Step [400/591], Loss: 0.0018\n",
      "Epoch [28/50], Step [500/591], Loss: 0.0669\n",
      "Epoch [29/50], Step [100/591], Loss: 0.0291\n",
      "Epoch [29/50], Step [200/591], Loss: 0.0745\n",
      "Epoch [29/50], Step [300/591], Loss: 0.0956\n",
      "Epoch [29/50], Step [400/591], Loss: 0.0675\n",
      "Epoch [29/50], Step [500/591], Loss: 0.0009\n",
      "Epoch [30/50], Step [100/591], Loss: 0.0037\n",
      "Epoch [30/50], Step [200/591], Loss: 0.0651\n",
      "Epoch [30/50], Step [300/591], Loss: 0.0182\n",
      "Epoch [30/50], Step [400/591], Loss: 0.0188\n",
      "Epoch [30/50], Step [500/591], Loss: 0.0586\n",
      "Epoch [31/50], Step [100/591], Loss: 0.1046\n",
      "Epoch [31/50], Step [200/591], Loss: 0.0535\n",
      "Epoch [31/50], Step [300/591], Loss: 0.0129\n",
      "Epoch [31/50], Step [400/591], Loss: 0.1376\n",
      "Epoch [31/50], Step [500/591], Loss: 0.0169\n",
      "Epoch [32/50], Step [100/591], Loss: 0.0082\n",
      "Epoch [32/50], Step [200/591], Loss: 0.0029\n",
      "Epoch [32/50], Step [300/591], Loss: 0.0100\n",
      "Epoch [32/50], Step [400/591], Loss: 0.0729\n",
      "Epoch [32/50], Step [500/591], Loss: 0.0236\n",
      "Epoch [33/50], Step [100/591], Loss: 0.0206\n",
      "Epoch [33/50], Step [200/591], Loss: 0.0026\n",
      "Epoch [33/50], Step [300/591], Loss: 0.0161\n",
      "Epoch [33/50], Step [400/591], Loss: 0.1502\n",
      "Epoch [33/50], Step [500/591], Loss: 0.0242\n",
      "Epoch [34/50], Step [100/591], Loss: 0.0267\n",
      "Epoch [34/50], Step [200/591], Loss: 0.0713\n",
      "Epoch [34/50], Step [300/591], Loss: 0.0164\n",
      "Epoch [34/50], Step [400/591], Loss: 0.0331\n",
      "Epoch [34/50], Step [500/591], Loss: 0.0086\n",
      "Epoch [35/50], Step [100/591], Loss: 0.0147\n",
      "Epoch [35/50], Step [200/591], Loss: 0.0253\n",
      "Epoch [35/50], Step [300/591], Loss: 0.0357\n",
      "Epoch [35/50], Step [400/591], Loss: 0.0104\n",
      "Epoch [35/50], Step [500/591], Loss: 0.0471\n",
      "Epoch [36/50], Step [100/591], Loss: 0.0171\n",
      "Epoch [36/50], Step [200/591], Loss: 0.0414\n",
      "Epoch [36/50], Step [300/591], Loss: 0.2195\n",
      "Epoch [36/50], Step [400/591], Loss: 0.1370\n",
      "Epoch [36/50], Step [500/591], Loss: 0.0126\n",
      "Epoch [37/50], Step [100/591], Loss: 0.0588\n",
      "Epoch [37/50], Step [200/591], Loss: 0.0145\n",
      "Epoch [37/50], Step [300/591], Loss: 0.0202\n",
      "Epoch [37/50], Step [400/591], Loss: 0.0788\n",
      "Epoch [37/50], Step [500/591], Loss: 0.0016\n",
      "Epoch [38/50], Step [100/591], Loss: 0.0008\n",
      "Epoch [38/50], Step [200/591], Loss: 0.0099\n",
      "Epoch [38/50], Step [300/591], Loss: 0.0696\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/50], Step [400/591], Loss: 0.0292\n",
      "Epoch [38/50], Step [500/591], Loss: 0.0229\n",
      "Epoch [39/50], Step [100/591], Loss: 0.1183\n",
      "Epoch [39/50], Step [200/591], Loss: 0.0080\n",
      "Epoch [39/50], Step [300/591], Loss: 0.0036\n",
      "Epoch [39/50], Step [400/591], Loss: 0.0049\n",
      "Epoch [39/50], Step [500/591], Loss: 0.0081\n",
      "Epoch [40/50], Step [100/591], Loss: 0.0021\n",
      "Epoch [40/50], Step [200/591], Loss: 0.0084\n",
      "Epoch [40/50], Step [300/591], Loss: 0.0084\n",
      "Epoch [40/50], Step [400/591], Loss: 0.0052\n",
      "Epoch [40/50], Step [500/591], Loss: 0.0897\n",
      "Epoch [41/50], Step [100/591], Loss: 0.1283\n",
      "Epoch [41/50], Step [200/591], Loss: 0.1037\n",
      "Epoch [41/50], Step [300/591], Loss: 0.0078\n",
      "Epoch [41/50], Step [400/591], Loss: 0.0051\n",
      "Epoch [41/50], Step [500/591], Loss: 0.0777\n",
      "Epoch [42/50], Step [100/591], Loss: 0.1608\n",
      "Epoch [42/50], Step [200/591], Loss: 0.0264\n",
      "Epoch [42/50], Step [300/591], Loss: 0.0091\n",
      "Epoch [42/50], Step [400/591], Loss: 0.0126\n",
      "Epoch [42/50], Step [500/591], Loss: 0.0012\n",
      "Epoch [43/50], Step [100/591], Loss: 0.0285\n",
      "Epoch [43/50], Step [200/591], Loss: 0.0026\n",
      "Epoch [43/50], Step [300/591], Loss: 0.0527\n",
      "Epoch [43/50], Step [400/591], Loss: 0.0108\n",
      "Epoch [43/50], Step [500/591], Loss: 0.0057\n",
      "Epoch [44/50], Step [100/591], Loss: 0.0231\n",
      "Epoch [44/50], Step [200/591], Loss: 0.1544\n",
      "Epoch [44/50], Step [300/591], Loss: 0.0560\n",
      "Epoch [44/50], Step [400/591], Loss: 0.0804\n",
      "Epoch [44/50], Step [500/591], Loss: 0.1289\n",
      "Epoch [45/50], Step [100/591], Loss: 0.0156\n",
      "Epoch [45/50], Step [200/591], Loss: 0.0012\n",
      "Epoch [45/50], Step [300/591], Loss: 0.0400\n",
      "Epoch [45/50], Step [400/591], Loss: 0.0037\n",
      "Epoch [45/50], Step [500/591], Loss: 0.0022\n",
      "Epoch [46/50], Step [100/591], Loss: 0.0048\n",
      "Epoch [46/50], Step [200/591], Loss: 0.1013\n",
      "Epoch [46/50], Step [300/591], Loss: 0.0059\n",
      "Epoch [46/50], Step [400/591], Loss: 0.0809\n",
      "Epoch [46/50], Step [500/591], Loss: 0.0666\n",
      "Epoch [47/50], Step [100/591], Loss: 0.0724\n",
      "Epoch [47/50], Step [200/591], Loss: 0.0481\n",
      "Epoch [47/50], Step [300/591], Loss: 0.0230\n",
      "Epoch [47/50], Step [400/591], Loss: 0.0186\n",
      "Epoch [47/50], Step [500/591], Loss: 0.0030\n",
      "Epoch [48/50], Step [100/591], Loss: 0.0014\n",
      "Epoch [48/50], Step [200/591], Loss: 0.0059\n",
      "Epoch [48/50], Step [300/591], Loss: 0.0453\n",
      "Epoch [48/50], Step [400/591], Loss: 0.0678\n",
      "Epoch [48/50], Step [500/591], Loss: 0.0040\n",
      "Epoch [49/50], Step [100/591], Loss: 0.0173\n",
      "Epoch [49/50], Step [200/591], Loss: 0.0202\n",
      "Epoch [49/50], Step [300/591], Loss: 0.0347\n",
      "Epoch [49/50], Step [400/591], Loss: 0.0793\n",
      "Epoch [49/50], Step [500/591], Loss: 0.0300\n",
      "Epoch [50/50], Step [100/591], Loss: 0.1689\n",
      "Epoch [50/50], Step [200/591], Loss: 0.0074\n",
      "Epoch [50/50], Step [300/591], Loss: 0.0457\n",
      "Epoch [50/50], Step [400/591], Loss: 0.1127\n",
      "Epoch [50/50], Step [500/591], Loss: 0.0519\n"
     ]
    }
   ],
   "source": [
    "# 训练模型\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, num_epochs, i+1, total_step, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the 10000 test images: 98.11904761904762 %\n"
     ]
    }
   ],
   "source": [
    "# 验证集\n",
    "# 节省计算资源，不去计算梯度\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in val_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Test Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 第一次测试 98.4523\n",
    "# 第二次测试 99.0952，但是在测试集上效果不佳，应该是过拟合了。\n",
    "# 第三次居然只有 97.8333"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 预测测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28000, 1, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "model.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n",
    "test = np.reshape(test, (-1,1,28,28))\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0,)\n",
      "(1000,)\n",
      "(2000,)\n",
      "(3000,)\n",
      "(4000,)\n",
      "(5000,)\n",
      "(6000,)\n",
      "(7000,)\n",
      "(8000,)\n",
      "(9000,)\n",
      "(10000,)\n",
      "(11000,)\n",
      "(12000,)\n",
      "(13000,)\n",
      "(14000,)\n",
      "(15000,)\n",
      "(16000,)\n",
      "(17000,)\n",
      "(18000,)\n",
      "(19000,)\n",
      "(20000,)\n",
      "(21000,)\n",
      "(22000,)\n",
      "(23000,)\n",
      "(24000,)\n",
      "(25000,)\n",
      "(26000,)\n",
      "(27000,)\n",
      "(28000,)\n"
     ]
    }
   ],
   "source": [
    "result= np.array([])\n",
    "print(result.shape)\n",
    "with torch.no_grad():\n",
    "    for i in range(0,len(test), 1000):\n",
    "        imageSet = test[i:i+1000]\n",
    "        imageSet = torch.Tensor(imageSet).to(device)\n",
    "        outputs = model(imageSet)\n",
    "        _,predicted = torch.max(outputs.data, 1)\n",
    "        result = np.append(result, predicted.cpu().numpy())\n",
    "        print(result.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28000,)\n"
     ]
    }
   ],
   "source": [
    "print(result.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成提交文件\n",
    "results = pd.Series(result,name=\"Label\")\n",
    "submission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\n",
    "submission.to_csv(\"test_result.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__Python VERSION: 3.6.5 |Anaconda, Inc.| (default, Apr 29 2018, 16:14:56) \n",
      "[GCC 7.2.0]\n",
      "__pyTorch VERSION: 0.4.1\n",
      "__CUDA VERSION\n",
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2017 NVIDIA Corporation\n",
      "Built on Fri_Sep__1_21:08:03_CDT_2017\n",
      "Cuda compilation tools, release 9.0, V9.0.176\n",
      "__CUDNN VERSION: 7102\n",
      "__Number CUDA Devices: 2\n",
      "__Devices\n",
      "Active CUDA Device: GPU 1\n",
      "Available devices  2\n",
      "Current cuda device  1\n"
     ]
    }
   ],
   "source": [
    "# 这一段可以用来查看当前GPU的情况\n",
    "import torch\n",
    "import sys\n",
    "print('__Python VERSION:', sys.version)\n",
    "print('__pyTorch VERSION:', torch.__version__)\n",
    "print('__CUDA VERSION')\n",
    "from subprocess import call\n",
    "# call([\"nvcc\", \"--version\"]) does not work\n",
    "! nvcc --version\n",
    "print('__CUDNN VERSION:', torch.backends.cudnn.version())\n",
    "print('__Number CUDA Devices:', torch.cuda.device_count())\n",
    "print('__Devices')\n",
    "call([\"nvidia-smi\", \"--format=csv\", \"--query-gpu=index,name,driver_version,memory.total,memory.used,memory.free\"])\n",
    "print('Active CUDA Device: GPU', torch.cuda.current_device())\n",
    "\n",
    "print ('Available devices ', torch.cuda.device_count())\n",
    "print ('Current cuda device ', torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
